---
title: "XGBoostExplainerが何をやっているか調べる"
author: Satoshi Kato (@katokohaku)
output: 
  html_document:
    keep_md: yes
    toc: yes
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
require(tidyverse)
require(magrittr)

knitr::opts_knit$set(
  progress = TRUE, 
  verbose = TRUE, 
  root.dir = "."
)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE
)
```

# 目的

今回は、インスタンスの予測結果が再構成されるプロセスをstep-by-stepで眺める。
`buildExplainer()`の中身を抜き書きしながら、都度、**何から何が取り出されているか**見ていく。


# 関連シリーズ

1. [とりあえず使ってみる](http://kato-kohaku-0.hatenablog.com/entry/2018/12/14/002253)
2. [予測結果の可視化プロセスをstep-by-stepで実行する](http://kato-kohaku-0.hatenablog.com/entry/2018/12/14/231803)
3. 予測結果を分解再構成するプロセスをstep-by-stepで実行する（この記事）
4. 学習したxgboostのルール抽出をstep-by-stepで実行する

# 準備

## XGBモデルの学習と予測

`xgboostExplainer`のマニュアルにあるexampleからコピペ。

```{r train.and.predict, message=FALSE, results="hide"}
require(tidyverse)
library(xgboost)
library(xgboostExplainer)

set.seed(123)

data(agaricus.train, package='xgboost')

X = as.matrix(agaricus.train$data)
y = agaricus.train$label
table(y)
train_idx = 1:5000

train.data = X[train_idx,]
test.data = X[-train_idx,]

xgb.train.data <- xgb.DMatrix(train.data, label = y[train_idx])
xgb.test.data <- xgb.DMatrix(test.data)

param <- list(objective = "binary:logistic")
xgb.model <- xgboost(param =param,  data = xgb.train.data, nrounds=3)

```
## 予測ルールを抽出する

`buildExplainer()`で、学習したxgboostのモデルから予測ルールを抽出する。

```{r, results="hide"}
library(xgboostExplainer)

explainer = buildExplainer(xgb.model,xgb.train.data, type="binary", base_score = 0.5, trees = NULL)

```

# 結果を分解再構成する

## overview

指定したインスタンスの予測結果を、`buildExplainer()`が学習したモデルから再構成した結果(breakdown)を眺める。

再構成の大まかな手順は以下の通り：

1. 指定したインスタンスが各roundでどのleafに落ちるか予測結果を得る
2. 各roundで該当するleafの各特徴量の予測値への貢献量(予測ルール)を得る
3. 2を集計し、round全体での予測ルールを得る


## 対象の予測

今回は省略のため、1インスタンスだけを対象として指定するが、下記idxは複数のインスタンスを指定するベクトルでもよい。

```{r}
require(data.table)
# breakdown = explainPredictions(xgb.model, explainer, slice(DMatrix, as.integer(idx)))
# function (xgb.model, explainer, data) 

DMatrix = xgb.test.data
idx = 2

data = slice(DMatrix, as.integer(idx))

nodes = predict(xgb.model, data, predleaf = TRUE)
print(nodes)

```

`xgboost:::predict.xgb.Booster()`は、`predleaf = TRUE`オプションを指定することで、あるインスタンスの予測時に、それぞれのroundのtreeでどのleafに落ちたか？を返してくれる

## 初期化

インスタンスの数（行）× Interceptを含むすべてのルール（列）からなるゼロ行列を準備する。

```{r}
colnames = names(explainer)[1:(ncol(explainer) - 2)]
  
preds_breakdown = data.table(matrix(0, nrow = nrow(nodes), ncol = length(colnames)))
setnames(preds_breakdown, colnames)
  
num_trees = ncol(nodes)

cat("\n\nExtracting the breakdown of each prediction...\n")

preds_breakdown.init <- preds_breakdown
```

## 対象のtreeの取り出し

今後のトレースを楽にするために「すべての行が0の列を削除し、残った列の列名を短縮する」関数を自作した。

```{r}
selectNonzeroToShort <- function(data, w=12){
  select_if(data,
            .predicate = function(x){ sum(abs(x)) > 0} , 
            .funs = function(x){ str_trunc(x, width=w, side="left") }) 
}

```

最初のtreeだけ少し丁寧にトレースする（残りは繰り返しなので省略）
```{r}
x=1

nodes_for_tree = nodes[, x]
nodes_for_tree
```

`buildExplainer()`でとりだしたLeafのうち、このroundで対象となる木のLeafを列挙。

```{r}
tree_breakdown = explainer[tree == x - 1]
tree_breakdown %>% selectNonzeroToShort()
  

```

## 対象のleafのとりだし

round=1のtreeのなかのLeaf ==`r nodes_for_tree`が、今回の予測ルール（予測値に各特徴量が寄与する変化量）。これを取り出して、`preds_breakdown`に足し合わせていく。

```{r}
preds_breakdown_for_tree = 
  tree_breakdown[match(nodes_for_tree, tree_breakdown$leaf), ]

print("preds_breakdown_for_tree")
preds_breakdown_for_tree %>%  
  selectNonzeroToShort(w=20) %>% 
  glimpse()

preds_breakdown = 
  preds_breakdown + 
  preds_breakdown_for_tree[,colnames, with = FALSE]

print("preds_breakdown")
preds_breakdown %>%  
  selectNonzeroToShort(w=20) %>% 
  glimpse()

```

すべてのroudsをまとめて実行すると、以下の通り。

```{r}
preds_breakdown <- preds_breakdown.init
for (x in 1:num_trees) {
  print(x)
  
  nodes_for_tree = nodes[, x]
  tree_breakdown = explainer[tree == x - 1]

  preds_breakdown_for_tree = 
    tree_breakdown[match(nodes_for_tree, tree_breakdown$leaf), ]
  
  print("preds_breakdown_for_tree")
  preds_breakdown_for_tree %>%  
    selectNonzeroToShort(w=20) %>% 
    glimpse()
  
  preds_breakdown = 
    preds_breakdown + 
    preds_breakdown_for_tree[,colnames, with = FALSE]
  
  print("preds_breakdown")
  preds_breakdown %>%  
    selectNonzeroToShort(w=20) %>% 
    glimpse()
}

# return(preds_breakdown)


```


## 検算

元実装の結果と合致してるか検算。分解再構成した結果の可視化。

```{r}
preds_breakdown %>% selectNonzeroToShort(w=20)

weight <- sum(preds_breakdown)
weight

prediction <- exp(weight)/(1+exp(weight))
prediction

showWaterfall(xgb.model, explainer, xgb.test.data, test.data,  2, type = "binary")

```

次回は、`buildExplainer()`が、どのような手続きで学習したxgboostのモデルから予測ルールを抽出しているのか詳細に見ていく。